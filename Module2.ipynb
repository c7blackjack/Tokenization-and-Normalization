{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the emoji package if not already installed\n",
    "#!pip install emoji\n",
    "#!pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import html\n",
    "from textacy import preprocessing\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/travis/mod2/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens/num_tokens\n",
    "    num_characters = 0\n",
    "    for i in tokens:\n",
    "        num_characters += len(i)\n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n"
     ]
    }
   ],
   "source": [
    "text = \"here is some example text with other example text here in this text\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: The benifeit to using assert in the function is that is ensures that the code is functioning within given parameters and desired outcomes and if they are not met, it will throw an assertion error with custom verbiage which is great for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "lyric_directory = str(data_location + lyrics_folder)\n",
    "lyric_df = pd.DataFrame()\n",
    "\n",
    "with os.scandir(lyric_directory) as artist:\n",
    "    for artist in artist:\n",
    "        if not artist.name.startswith('.') and artist.is_dir():\n",
    "            with os.scandir(artist.path) as songs:\n",
    "                    for song in songs:\n",
    "                        if not song.name.startswith('.'):\n",
    "                            with open(song.path) as f:\n",
    "                                lines = f.read()\n",
    "                            lyric_df = lyric_df.append(pd.DataFrame({'Artist': artist.name, 'song': song.name, 'content': lines}, index=[0]), ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>song</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_dowhatyougottado.txt</td>\n",
       "      <td>\"Do What You Gotta Do\"\\n\\n\\n\\nGirl I can under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_88days.txt</td>\n",
       "      <td>\"88 Days\"\\n\\n\\n\\nI light a candle in the morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_ayounggirluneenfante.txt</td>\n",
       "      <td>\"A Young Girl (Une Enfante)\"\\n\\n\\n\\nShe left h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_shouldhaveknown106828.txt</td>\n",
       "      <td>\"Should Have Known\"\\n\\n\\n\\nI should have seen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_igotosleep.txt</td>\n",
       "      <td>\"I Go To Sleep\"\\n\\n\\n\\nWhen I look up from my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_clicksong.txt</td>\n",
       "      <td>\"Click Song\"\\n\\n\\n\\nIgqira lendlela nguqo ngqo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_beach2k20.txt</td>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_whentheloveisgone.txt</td>\n",
       "      <td>\"When The Love Is Gone\"\\n\\n\\n\\nWhen the love i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_alfie.txt</td>\n",
       "      <td>\"Alfie\"\\n\\n\\n\\nWhat's it all about, Alfie?\\nIs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_bangbang.txt</td>\n",
       "      <td>\"Bang-Bang\"\\n\\n\\n\\nBang bang you shot me down\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Artist                             song  \\\n",
       "263   cher        cher_dowhatyougottado.txt   \n",
       "79   robyn                 robyn_88days.txt   \n",
       "132   cher    cher_ayounggirluneenfante.txt   \n",
       "25   robyn  robyn_shouldhaveknown106828.txt   \n",
       "342   cher              cher_igotosleep.txt   \n",
       "277   cher               cher_clicksong.txt   \n",
       "2    robyn              robyn_beach2k20.txt   \n",
       "371   cher       cher_whentheloveisgone.txt   \n",
       "178   cher                   cher_alfie.txt   \n",
       "145   cher                cher_bangbang.txt   \n",
       "\n",
       "                                               content  \n",
       "263  \"Do What You Gotta Do\"\\n\\n\\n\\nGirl I can under...  \n",
       "79   \"88 Days\"\\n\\n\\n\\nI light a candle in the morni...  \n",
       "132  \"A Young Girl (Une Enfante)\"\\n\\n\\n\\nShe left h...  \n",
       "25   \"Should Have Known\"\\n\\n\\n\\nI should have seen ...  \n",
       "342  \"I Go To Sleep\"\\n\\n\\n\\nWhen I look up from my ...  \n",
       "277  \"Click Song\"\\n\\n\\n\\nIgqira lendlela nguqo ngqo...  \n",
       "2    \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...  \n",
       "371  \"When The Love Is Gone\"\\n\\n\\n\\nWhen the love i...  \n",
       "178  \"Alfie\"\\n\\n\\n\\nWhat's it all about, Alfie?\\nIs...  \n",
       "145  \"Bang-Bang\"\\n\\n\\n\\nBang bang you shot me down\\...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 624: expected 7 fields, saw 12\\nSkipping line 17506: expected 7 fields, saw 12\\nSkipping line 104621: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 188924: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 301600: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 429936: expected 7 fields, saw 12\\nSkipping line 444405: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 677792: expected 7 fields, saw 12\\nSkipping line 773482: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 818258: expected 7 fields, saw 12\\nSkipping line 895225: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 955213: expected 7 fields, saw 10\\nSkipping line 994827: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 1246039: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 1569117: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 2127250: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 2335031: expected 7 fields, saw 12\\n'\n",
      "b'Skipping line 2681065: expected 7 fields, saw 10\\n'\n",
      "b'Skipping line 3147696: expected 7 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read in the twitter data\n",
    "twitter_directory = str(data_location + twitter_folder)\n",
    "twitter_df = pd.DataFrame()\n",
    "\n",
    "cher_followers_df = pd.read_csv(twitter_directory + 'cher_followers.txt', sep='\\t')\n",
    "cher_followers_data_df = pd.read_csv(twitter_directory + 'cher_followers_data.txt', sep='\\t',header=0, error_bad_lines=False);\n",
    "\n",
    "cher_followers_data_df = cher_followers_data_df.sample(75000)\n",
    "\n",
    "robyn_followers_df = pd.read_csv(twitter_directory + 'robynkonichiwa_followers.txt', sep='\\t')\n",
    "robyn_followers_data_df = pd.read_csv(twitter_directory + 'robynkonichiwa_followers_data.txt', sep='\\t',header=0, error_bad_lines=False);\n",
    "robyn_followers_data_df = robyn_followers_data_df.sample(75000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robyn_followers_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cher_followers_data_df['description'] = cher_followers_data_df['description'].astype('string')\n",
    "cher_followers_data_df['description'] = cher_followers_data_df['description'].fillna('')\n",
    "\n",
    "robyn_followers_data_df['description'] = robyn_followers_data_df['description'].astype('string')\n",
    "robyn_followers_data_df['description'] = robyn_followers_data_df['description'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean twitter data here\n",
    "\n",
    "## This calculates the impurity in an instance of tokens, used to find characters worth removing\n",
    "RE_SUSPICIOUS = re.compile(r'[&#<>{}\\[\\]\\\\]')\n",
    "def impurity(text, min_len=10):\n",
    "    \"\"\"returns the share of suspicious characters in a text\"\"\" \n",
    "    if text == None or len(text) < min_len:\n",
    "        return 0 \n",
    "    else:\n",
    "        return len(RE_SUSPICIOUS.findall(text))/len(text)\n",
    "    print(impurity(text))\n",
    "\n",
    "## Function to clean the text by removing matches on the regex rules\n",
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text) # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'##',' ',text)\n",
    "    text = re.sub(r'{{_}}',' ',text)\n",
    "    text = re.sub(r'/\\/',' ',text)\n",
    "    text = re.sub(r'//\\\\',' ',text)\n",
    "    text = re.sub(r'\\\\',' ',text)\n",
    "    #Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def normalize(text):\n",
    "    text = preprocessing.normalize.hyphenated_words(text)\n",
    "    text = preprocessing.normalize.quotation_marks(text)\n",
    "    text = preprocessing.normalize.unicode(text)\n",
    "    text = preprocessing.remove.accents(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    return [t for t in tokens if t.lower() not in stop_words]\n",
    "\n",
    "pipeline = [str.lower, tokenize, remove_stop]\n",
    "\n",
    "def prepare(text, pipeline): \n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2063875</th>\n",
       "      <td>doctormaori101</td>\n",
       "      <td>Doctormaori101</td>\n",
       "      <td>3.045958e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133291</th>\n",
       "      <td>ganeshbaral11</td>\n",
       "      <td>Ganesh prasad Baral</td>\n",
       "      <td>2.953919e+09</td>\n",
       "      <td>Kathamandu,Nepal</td>\n",
       "      <td>10.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>CA Student at Institute of Chartered Accountan...</td>\n",
       "      <td>CA Student at Institute of Chartered Accountan...</td>\n",
       "      <td>[ca, student, institute, chartered, accountant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216491</th>\n",
       "      <td>VerrecktKelly</td>\n",
       "      <td>Kelly Verreckt</td>\n",
       "      <td>9.156692e+17</td>\n",
       "      <td>Tessenderlo, Belgi√´</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668535</th>\n",
       "      <td>RyanAnthony_J</td>\n",
       "      <td>Ryan Jones</td>\n",
       "      <td>4.489908e+08</td>\n",
       "      <td>England</td>\n",
       "      <td>69.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>running on the road to fortune!</td>\n",
       "      <td>running on the road to fortune</td>\n",
       "      <td>[running, road, fortune]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316372</th>\n",
       "      <td>phashainah</td>\n",
       "      <td>inah phasha</td>\n",
       "      <td>2.715367e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            screen_name                 name            id  \\\n",
       "2063875  doctormaori101       Doctormaori101  3.045958e+09   \n",
       "2133291   ganeshbaral11  Ganesh prasad Baral  2.953919e+09   \n",
       "1216491   VerrecktKelly       Kelly Verreckt  9.156692e+17   \n",
       "2668535   RyanAnthony_J           Ryan Jones  4.489908e+08   \n",
       "2316372      phashainah          inah phasha  2.715367e+09   \n",
       "\n",
       "                    location  followers_count  friends_count  \\\n",
       "2063875                  NaN             25.0          454.0   \n",
       "2133291     Kathamandu,Nepal             10.0          148.0   \n",
       "1216491  Tessenderlo, Belgi√´              2.0          123.0   \n",
       "2668535             England              69.0          212.0   \n",
       "2316372                  NaN              0.0           26.0   \n",
       "\n",
       "                                               description  \\\n",
       "2063875                                                      \n",
       "2133291  CA Student at Institute of Chartered Accountan...   \n",
       "1216491                                                      \n",
       "2668535                    running on the road to fortune!   \n",
       "2316372                                                      \n",
       "\n",
       "                                                clean_text  \\\n",
       "2063875                                                      \n",
       "2133291  CA Student at Institute of Chartered Accountan...   \n",
       "1216491                                                      \n",
       "2668535                     running on the road to fortune   \n",
       "2316372                                                      \n",
       "\n",
       "                                                    tokens  \n",
       "2063875                                                 []  \n",
       "2133291  [ca, student, institute, chartered, accountant...  \n",
       "1216491                                                 []  \n",
       "2668535                           [running, road, fortune]  \n",
       "2316372                                                 []  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cher_followers_data_df['clean_text'] = cher_followers_data_df['description'].map(clean)\n",
    "cher_followers_data_df['clean_text'] = cher_followers_data_df['clean_text'].astype('string')\n",
    "cher_followers_data_df['clean_text'] = cher_followers_data_df['clean_text'].map(normalize)\n",
    "cher_followers_data_df['tokens'] = cher_followers_data_df['clean_text'].apply(prepare, pipeline=pipeline)\n",
    "cher_followers_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254169</th>\n",
       "      <td>KessariXO</td>\n",
       "      <td>KESSARI</td>\n",
       "      <td>515856434</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>27</td>\n",
       "      <td>228</td>\n",
       "      <td>I'm a model and a singer. Follow me on Faceboo...</td>\n",
       "      <td>I m a model and a singer  Follow me on Faceboo...</td>\n",
       "      <td>[model, singer, follow, facebook, http, co, lv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342790</th>\n",
       "      <td>bigmue</td>\n",
       "      <td>Wolfgang M√ºller</td>\n",
       "      <td>9576622</td>\n",
       "      <td>iPhone: 48.158478,11.649231</td>\n",
       "      <td>1051</td>\n",
       "      <td>1804</td>\n",
       "      <td>don¬¥t follow me, i¬¥m lost too</td>\n",
       "      <td>don t follow me  i m lost too</td>\n",
       "      <td>[follow, lost]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221037</th>\n",
       "      <td>zarahthegr8</td>\n",
       "      <td>Sarah Williams</td>\n",
       "      <td>727702934</td>\n",
       "      <td>Klippan, Sk√•ne, Sweden</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>Mom of 2 amazing kids Theodor and Enya. Canadi...</td>\n",
       "      <td>Mom of 2 amazing kids Theodor and Enya  Canadi...</td>\n",
       "      <td>[mom, amazing, kids, theodor, enya, canadian, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66396</th>\n",
       "      <td>Kiro95383134</td>\n",
       "      <td>Kiro</td>\n",
       "      <td>4892313323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343792</th>\n",
       "      <td>CaleyZ</td>\n",
       "      <td>Caley Zingerle</td>\n",
       "      <td>55871228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         screen_name             name          id  \\\n",
       "254169     KessariXO          KESSARI   515856434   \n",
       "342790        bigmue  Wolfgang M√ºller     9576622   \n",
       "221037   zarahthegr8   Sarah Williams   727702934   \n",
       "66396   Kiro95383134             Kiro  4892313323   \n",
       "343792        CaleyZ   Caley Zingerle    55871228   \n",
       "\n",
       "                           location  followers_count  friends_count  \\\n",
       "254169                  Los Angeles               27            228   \n",
       "342790  iPhone: 48.158478,11.649231             1051           1804   \n",
       "221037       Klippan, Sk√•ne, Sweden               20            134   \n",
       "66396                           NaN                3             33   \n",
       "343792                          NaN                0             20   \n",
       "\n",
       "                                              description  \\\n",
       "254169  I'm a model and a singer. Follow me on Faceboo...   \n",
       "342790                      don¬¥t follow me, i¬¥m lost too   \n",
       "221037  Mom of 2 amazing kids Theodor and Enya. Canadi...   \n",
       "66396                                                       \n",
       "343792                                                      \n",
       "\n",
       "                                               clean_text  \\\n",
       "254169  I m a model and a singer  Follow me on Faceboo...   \n",
       "342790                      don t follow me  i m lost too   \n",
       "221037  Mom of 2 amazing kids Theodor and Enya  Canadi...   \n",
       "66396                                                       \n",
       "343792                                                      \n",
       "\n",
       "                                                   tokens  \n",
       "254169  [model, singer, follow, facebook, http, co, lv...  \n",
       "342790                                     [follow, lost]  \n",
       "221037  [mom, amazing, kids, theodor, enya, canadian, ...  \n",
       "66396                                                  []  \n",
       "343792                                                 []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robyn_followers_data_df['clean_text'] = robyn_followers_data_df['description'].map(clean)\n",
    "robyn_followers_data_df['clean_text'] = robyn_followers_data_df['clean_text'].astype('string')\n",
    "robyn_followers_data_df['clean_text'] = robyn_followers_data_df['clean_text'].map(normalize)\n",
    "robyn_followers_data_df['tokens'] = robyn_followers_data_df['clean_text'].apply(prepare, pipeline=pipeline)\n",
    "robyn_followers_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean lyrics data here\n",
    "lyric_df['clean_text'] = lyric_df['content'].map(clean)\n",
    "lyric_df['clean_text'] = lyric_df['clean_text'].map(normalize)\n",
    "lyric_df['tokens'] = lyric_df['clean_text'].apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df.head()\n",
    "robyn_lyric_df = pd.DataFrame(lyric_df[lyric_df['Artist'] == 'robyn'])\n",
    "cher_lyric_df = pd.DataFrame(lyric_df[lyric_df['Artist'] == 'cher'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>song</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_includemeout.txt</td>\n",
       "      <td>\"Include Me Out\"\\n\\n\\n\\nIt is really very simp...</td>\n",
       "      <td>Include Me Out  It is really very simple Just ...</td>\n",
       "      <td>[include, really, simple, single, pulse, repea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_electric.txt</td>\n",
       "      <td>\"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...</td>\n",
       "      <td>Electric  Electric    It s electric It s a nat...</td>\n",
       "      <td>[electric, electric, electric, natural, high, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_beach2k20.txt</td>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "      <td>Beach 2K20   So you wanna go out  How you gonn...</td>\n",
       "      <td>[beach, 2k20, wanna, go, gonna, get, ok, call,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_lovekills.txt</td>\n",
       "      <td>\"Love Kills\"\\n\\n\\n\\nIf you're looking for love...</td>\n",
       "      <td>Love Kills  If you re looking for love Get a h...</td>\n",
       "      <td>[love, kills, looking, love, get, heart, made,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_timemachine.txt</td>\n",
       "      <td>\"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...</td>\n",
       "      <td>Time Machine  Hey  what did I do  Can t believ...</td>\n",
       "      <td>[time, machine, hey, believe, fit, threw, stup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Artist                    song  \\\n",
       "0  robyn  robyn_includemeout.txt   \n",
       "1  robyn      robyn_electric.txt   \n",
       "2  robyn     robyn_beach2k20.txt   \n",
       "3  robyn     robyn_lovekills.txt   \n",
       "4  robyn   robyn_timemachine.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  \"Include Me Out\"\\n\\n\\n\\nIt is really very simp...   \n",
       "1  \"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...   \n",
       "2  \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...   \n",
       "3  \"Love Kills\"\\n\\n\\n\\nIf you're looking for love...   \n",
       "4  \"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  Include Me Out  It is really very simple Just ...   \n",
       "1  Electric  Electric    It s electric It s a nat...   \n",
       "2  Beach 2K20   So you wanna go out  How you gonn...   \n",
       "3  Love Kills  If you re looking for love Get a h...   \n",
       "4  Time Machine  Hey  what did I do  Can t believ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [include, really, simple, single, pulse, repea...  \n",
       "1  [electric, electric, electric, natural, high, ...  \n",
       "2  [beach, 2k20, wanna, go, gonna, get, ok, call,...  \n",
       "3  [love, kills, looking, love, get, heart, made,...  \n",
       "4  [time, machine, hey, believe, fit, threw, stup...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robyn_lyric_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist_descriptions = dict()\n",
    "# for artist in your_artists:\n",
    "#     artist_descriptions[artist] = []\n",
    "#     for description in df[df[\"artist\"] == artist][\"description\"]:\n",
    "#        artist_descriptions[artist].extend(description.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cher_lyrics = []\n",
    "for description in cher_lyric_df[\"clean_text\"]:\n",
    "    cher_lyrics.extend(description.split())\n",
    "\n",
    "cher_followers = []\n",
    "for description in cher_followers_data_df[\"clean_text\"]:\n",
    "    cher_followers.extend(description.split())\n",
    "    \n",
    "robyn_lyrics = []\n",
    "for description in robyn_lyric_df[\"clean_text\"]:\n",
    "    robyn_lyrics.extend(description.split())\n",
    "    \n",
    "robyn_followers = []\n",
    "for description in robyn_followers_data_df[\"clean_text\"]:\n",
    "    robyn_followers.extend(description.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher Lyrics Descriptive Statistics\n",
      "There are 73966 tokens in the data.\n",
      "There are 4579 unique tokens in the data.\n",
      "There are 264181 characters in the data.\n",
      "The lexical diversity is 0.062 in the data.\n",
      "[73966, 4579, 0.06190682205337587, 264181]\n",
      "count                                                   316\n",
      "unique                                                  316\n",
      "top       [hate, sleep, alone, thing, could, good, love,...\n",
      "freq                                                      1\n",
      "Name: tokens, dtype: object\n",
      "\n",
      "\n",
      "Cher Followers Descriptive Statistics\n",
      "There are 447550 tokens in the data.\n",
      "There are 70386 unique tokens in the data.\n",
      "There are 2094326 characters in the data.\n",
      "The lexical diversity is 0.157 in the data.\n",
      "[447550, 70386, 0.15726957881800915, 2094326]\n",
      "count     75000\n",
      "unique    35048\n",
      "top          []\n",
      "freq      38640\n",
      "Name: tokens, dtype: object\n",
      "\n",
      "\n",
      "Robyn Lyrics Descriptive Statistics\n",
      "There are 31177 tokens in the data.\n",
      "There are 2642 unique tokens in the data.\n",
      "There are 111836 characters in the data.\n",
      "The lexical diversity is 0.085 in the data.\n",
      "[31177, 2642, 0.08474195721204734, 111836]\n",
      "count                                                   104\n",
      "unique                                                   95\n",
      "top       [fembot, got, news, fembots, feelings, split, ...\n",
      "freq                                                      2\n",
      "Name: tokens, dtype: object\n",
      "\n",
      "\n",
      "Robyn Followers Descriptive Statistics\n",
      "There are 457657 tokens in the data.\n",
      "There are 85999 unique tokens in the data.\n",
      "There are 2248586 characters in the data.\n",
      "The lexical diversity is 0.188 in the data.\n",
      "[457657, 85999, 0.18791147081766477, 2248586]\n",
      "count     75000\n",
      "unique    37702\n",
      "top          []\n",
      "freq      36169\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Cher Lyrics Descriptive Statistics')\n",
    "print(descriptive_stats(cher_lyrics))\n",
    "print(cher_lyric_df[\"tokens\"].describe(include='O').T)\n",
    "print('\\n')\n",
    "print('Cher Followers Descriptive Statistics')\n",
    "print(descriptive_stats(cher_followers))\n",
    "print(cher_followers_data_df[\"tokens\"].describe(include='O').T)\n",
    "print('\\n')\n",
    "print('Robyn Lyrics Descriptive Statistics')\n",
    "print(descriptive_stats(robyn_lyrics))\n",
    "print(robyn_lyric_df[\"tokens\"].describe(include='O').T)\n",
    "print('\\n')\n",
    "print('Robyn Followers Descriptive Statistics')\n",
    "print(descriptive_stats(robyn_followers))\n",
    "print(robyn_followers_data_df[\"tokens\"].describe(include='O').T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: The top words most likely would wind up being stop words which would provide little usable information\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: I believed the lexical value to be much higher than they were. However when considering the genre of music that the two artists are part of, the genre typically has similar themes and similar structures which consists of a significant amount of chorus and repetitive sections of a song.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return(emoji.is_emoji(s))\n",
    "\n",
    "assert(is_emoji(\"‚ù§Ô∏è\"))\n",
    "assert(not is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emojis üòÅ\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cher_followers_desc = []\n",
    "for description in cher_followers_data_df[\"description\"]:\n",
    "    cher_followers_desc.extend(description.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('‚ù§Ô∏è', 266), ('üè≥Ô∏è\\u200düåà', 258), ('‚ù§', 199), ('‚ô•', 185), ('‚ú®', 152), ('üåà', 98), ('üíô', 71), ('üíï', 59), ('üíú', 56), ('üá∫üá∏', 54)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "emoji_tokens = []\n",
    "for token in cher_followers_desc:\n",
    "    if is_emoji(token) == True:\n",
    "        emoji_tokens.append(token)\n",
    "counter = Counter(emoji_tokens)\n",
    "most_common = counter.most_common(10)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#BLM', 154), ('#Resist', 112), ('#BlackLivesMatter', 89), ('#FBR', 62), ('#resist', 53), ('#1', 48), ('#TheResistance', 47), ('#blacklivesmatter', 43), ('#Resistance', 31), ('#RESIST', 26)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your code here\n",
    "hash_tokens = []\n",
    "for token in cher_followers_desc:\n",
    "    if re.match('(?:#)([A-Za-z0-9_](?:(?:[A-Za-z0-9_]|(?:\\.(?!\\.))){0,28}(?:[A-Za-z0-9_]))?)', token):\n",
    "        hash_tokens.append(token)\n",
    "counter = Counter(hash_tokens) \n",
    "most_common = counter.most_common(10)\n",
    "\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_desc = []\n",
    "for title in lyric_df[\"content\"]:\n",
    "    title = title.splitlines()[0]\n",
    "    lyrics_desc.append(title.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 36), ('To', 34), ('You', 25), ('\"The', 25), ('Of', 23), ('\"I', 22), ('A', 18), ('Me\"', 17), ('Love', 17), ('You\"', 17)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "song_tokens = []\n",
    "for token in lyrics_desc:\n",
    "    song_tokens.extend(token)\n",
    "counter = Counter(song_tokens) \n",
    "most_common = counter.most_common(10)\n",
    "\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: This matches on one to unlimited amount of whitespace characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your lyric length comparison chart here. \n",
    "len_df = lyric_df[['Artist','content']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>content</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Go Now\"\\n\\n\\n\\nWe've already said...goodbye.\\...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"The First Time\"\\n\\n\\n\\nOh I heard a rooster c...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Save Up All Your Tears\"\\n\\n\\n\\nI can't figure...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"The Sun Ain't Gonna Shine Anymore\"\\n\\n\\n\\nLon...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Holy Smoke\"\\n\\n\\n\\nWhere do we draw the line ...</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"How Long Has This Been Going On\"\\n\\n\\n\\nI cou...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"O Baby\"\\n\\n\\n\\n[Chorus:]\\nO baby you're makin...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"SOS\"\\n\\n\\n\\nWhere are those happy days, they ...</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Love Enough\"\\n\\n\\n\\nSomething goes wrong,Some...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"The Long And Winding Road\"\\n\\n\\n\\nThe long an...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Don't Think Twice\"\\n\\n\\n\\nIt ain't no use to ...</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Be Mine!\"\\n\\n\\n\\nIt's a good thing tears neve...</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"It's A Cryin' Shame\"\\n\\n\\n\\nLove walk out the...</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Send To Robin Immediately\"\\n\\n\\n\\nBaby forgiv...</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"My Song (Too Far Gone)\"\\n\\n\\n\\nHe was just an...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Look At Me\"\\n\\n\\n\\nLook at me \\nTell me what ...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Cry Myself To Sleep\"\\n\\n\\n\\nEvery night, I la...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Should Have Known\"\\n\\n\\n\\nI should have seen ...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>robyn</td>\n",
       "      <td>\"Konichiwa Bitches\"\\n\\n\\n\\nYou wanna rumble in...</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Artist                                            content  song_length\n",
       "309   cher  \"Go Now\"\\n\\n\\n\\nWe've already said...goodbye.\\...          181\n",
       "313   cher  \"The First Time\"\\n\\n\\n\\nOh I heard a rooster c...          136\n",
       "242   cher  \"Save Up All Your Tears\"\\n\\n\\n\\nI can't figure...          416\n",
       "304   cher  \"The Sun Ain't Gonna Shine Anymore\"\\n\\n\\n\\nLon...          187\n",
       "264   cher  \"Holy Smoke\"\\n\\n\\n\\nWhere do we draw the line ...          306\n",
       "170   cher  \"How Long Has This Been Going On\"\\n\\n\\n\\nI cou...          206\n",
       "19   robyn  \"O Baby\"\\n\\n\\n\\n[Chorus:]\\nO baby you're makin...          170\n",
       "172   cher  \"SOS\"\\n\\n\\n\\nWhere are those happy days, they ...          255\n",
       "140   cher  \"Love Enough\"\\n\\n\\n\\nSomething goes wrong,Some...          200\n",
       "165   cher  \"The Long And Winding Road\"\\n\\n\\n\\nThe long an...          156\n",
       "121   cher  \"Don't Think Twice\"\\n\\n\\n\\nIt ain't no use to ...          251\n",
       "9    robyn  \"Be Mine!\"\\n\\n\\n\\nIt's a good thing tears neve...          386\n",
       "321   cher  \"It's A Cryin' Shame\"\\n\\n\\n\\nLove walk out the...          296\n",
       "83   robyn  \"Send To Robin Immediately\"\\n\\n\\n\\nBaby forgiv...          192\n",
       "2    robyn  \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...          292\n",
       "215   cher  \"My Song (Too Far Gone)\"\\n\\n\\n\\nHe was just an...          228\n",
       "252   cher  \"Look At Me\"\\n\\n\\n\\nLook at me \\nTell me what ...          110\n",
       "344   cher  \"Cry Myself To Sleep\"\\n\\n\\n\\nEvery night, I la...          123\n",
       "11   robyn  \"Should Have Known\"\\n\\n\\n\\nI should have seen ...          226\n",
       "86   robyn  \"Konichiwa Bitches\"\\n\\n\\n\\nYou wanna rumble in...          337"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_length = []\n",
    "for i in len_df['content']:\n",
    "    text = tokenize_lyrics(str(i))\n",
    "    #text = len(text)\n",
    "    song_length.append(len(text))\n",
    "len_df['song_length'] = song_length\n",
    "len_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist\n",
       "cher     AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "robyn    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: song_length, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZZElEQVR4nO3df5BV5Z3n8ffHDohBp1AgiUOrNLMYRUXFFjFxddVVgXElzJos1E4grIpMYNfR2iQQ3ZitKRNX4zhxx5LBBGuI44rx1/YSthRHE8oqGWgUBASko0RaGCVk1SH+AOS7f5zT5nLtvn0O3Ye+l/t5Vd3qe5/zfM99vtrw5Tk/nqOIwMzMLKsj+noAZmZWW1w4zMwsFxcOMzPLxYXDzMxyceEwM7NcPtPXAzgUhgwZEsOHD+/rYZiZ1ZTVq1f/NiKGlrfXReEYPnw4ra2tfT0MM7OaIuk3nbX7UJWZmeXiwmFmZrm4cJiZWS51cY7DzKySvXv30t7ezocfftjXQ+kTAwYMoLGxkX79+mXq78JhZnWvvb2dY445huHDhyOpr4dzSEUEu3btor29naampkwxPlRlZnXvww8/ZPDgwXVXNAAkMXjw4FyzLRcOMzOoy6LRIW/uLhxmZpaLz3GYmZW5e9mrvbq/Gy87+aDivvGNb3DllVdy9dVX9+p4esqFww5Kb//BKnWwf8jM7A8igojgiCN6/8CSD1WZmVWJRYsWMXr0aM4880y+/vWvA7B8+XK+9KUvMWLECB599NFP+t55552ce+65jB49mltvvRWArVu3cuqpp/LNb36TMWPGsG3btkLG6cJhZlYFNmzYwG233cazzz7L2rVr+fGPfwzAjh07eP7551myZAlz584F4Omnn2bLli2sXLmSNWvWsHr1apYvXw7A5s2bmTZtGi+99BInnXRSIWP1oSozsyrw7LPPcvXVVzNkyBAAjjvuOAC+8pWvcMQRRzBq1CjeeustICkcTz/9NGeffTYAu3fvZsuWLZx44omcdNJJjBs3rtCxunCYmVWBiOj0stgjjzzygD4dP+fNm8f1119/QN+tW7cycODAYgeKD1WZmVWFSy+9lEceeYRdu3YB8Lvf/a7LvldccQULFy5k9+7dALz55pu8/fbbh2ScUPCMQ9J44MdAA/CTiLi9bLvS7ROB94FvRMSL3cVK+s/AHGAf8IuI+HaReZhZfemLK/tOO+00br75Zi666CIaGho+OQzVmcsvv5yNGzdy/vnnA3D00Ufz4IMP0tDQcEjGWljhkNQA3AtcBrQDqyS1RMQrJd0mACPT13nAfcB5lWIlXQxMAkZHxEeSPldUDmZmh9L06dOZPn16l9s7ZhgAN9xwAzfccMOn+qxfv76QsZUq8lDVWKAtIl6LiD3AwyR/4ZeaBCyKxApgkKTju4n9C+D2iPgIICIO3fzMzMwKLRzDgNKLiNvTtix9KsWeDPxrSf8k6VeSzu3syyXNlNQqqXXnzp09SMPMzEoVWTg6WzUrMvapFPsZ4FhgHPAt4BF1cilCRCyIiOaIaB469FPPWjczs4NU5MnxduCEks+NwPaMffpXiG0HHo/kurSVkvYDQwBPK8zMDoEiZxyrgJGSmiT1B6YALWV9WoBpSowD3o2IHd3EPglcAiDpZJIi89sC8zAzsxKFzTgiYp+kOcBTJJfULoyIDZJmpdvnA0tJLsVtI7kcd0al2HTXC4GFktYDe4Dp0XFXjJmZFa7Q+zgiYilJcShtm1/yPoDZWWPT9j3An/fuSM3MSjz3w97d38XzemU3v/zlL/nRj37EkiVLemV/B8t3jpuZVZmIYP/+/X09jC65cJiZVYHyJdGvueYaTj/9dM444wwWL178Sb/33nuPyZMnM2rUKGbNmsX+/fv56U9/yo033vhJn/vvv5+bbrrpk31ed911nHbaaVx++eV88MEHPR6rC4eZWZXoWBL9lltuob29nbVr1/LMM8/wrW99ix07dgCwcuVK7rrrLtatW8evf/1rHn/8caZMmUJLSwt79+4F4IEHHmDGjBkAbNmyhdmzZ7NhwwYGDRrEY4891uNxunCYmVWJjiXRn3/+eaZOnUpDQwOf//znueiii1i1ahUAY8eOZcSIETQ0NDB16lSef/55Bg4cyCWXXMKSJUvYtGkTe/fu5YwzzgCgqamJs846C4BzzjmHrVu39nicXlbdzKxKdCyJXulC0fL7nTs+X3vttfzgBz/glFNO+WS2AQcuy97Q0OBDVWZmh6MLL7yQxYsX8/HHH7Nz506WL1/O2LFjgeRQ1euvv87+/ftZvHgxF1xwAQDnnXce27Zt46GHHmLq1KmFjs8zDjOzcr10+ezBmjx5Mi+88AJnnnkmkrjjjjv4whe+wKZNmzj//POZO3cu69at48ILL2Ty5MmfxH3ta19jzZo1HHvssYWOT/Vw71xzc3O0trb29TAOK3cve7WwfffFsxCsvm3cuJFTTz21r4fRY1deeSU33ngjl156ae7Yzv4bSFodEc3lfX2oysysxr3zzjucfPLJHHXUUQdVNPLyoSozsxo3aNAgXn21uKMA5TzjMDOj8pVMh7u8ubtwmFndGzBgALt27arL4hER7Nq1iwEDBmSO8aEqM6t7jY2NtLe3U69PCx0wYACNjY2Z+7twmFnd69evH01NTX09jJrhQ1VmZpaLC4eZmeXiwmFmZrm4cJiZWS4uHGZmlosLh5mZ5eLCYWZmubhwmJlZLi4cZmaWiwuHmZnlUmjhkDRe0mZJbZLmdrJdku5Jt78saUx3sZK+L+lNSWvS18QiczAzswMVVjgkNQD3AhOAUcBUSaPKuk0ARqavmcB9GWPvjoiz0tfSonIwM7NPK3LGMRZoi4jXImIP8DAwqazPJGBRJFYAgyQdnzHWzMz6QJGFYxiwreRze9qWpU93sXPSQ1sLJXX6VHZJMyW1Smqt16WSzcyKUGThUCdt5U9J6apPpdj7gD8BzgJ2AHd19uURsSAimiOieejQoZkGbGZm3SvyeRztwAklnxuB7Rn79O8qNiLe6miUdD+wpPeGbGZm3SlyxrEKGCmpSVJ/YArQUtanBZiWXl01Dng3InZUik3PgXSYDKwvMAczMytT2IwjIvZJmgM8BTQACyNig6RZ6fb5wFJgItAGvA/MqBSb7voOSWeRHLraClxfVA5mZvZphT46Nr1UdmlZ2/yS9wHMzhqbtn+9l4dpZmY5+M5xMzPLxYXDzMxyceEwM7NcXDjMzCwXFw4zM8vFhcPMzHJx4TAzs1xcOMzMLBcXDjMzy8WFw8zMcnHhMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcXDjMzCwXFw4zM8ul0CcAmh2Mu5e9Wti+b7zs5ML2bVYvPOMwM7NcXDjMzCwXFw4zM8vFhcPMzHJx4TAzs1xcOMzMLJdCC4ek8ZI2S2qTNLeT7ZJ0T7r9ZUljcsT+V0khaUiROZiZ2YEKKxySGoB7gQnAKGCqpFFl3SYAI9PXTOC+LLGSTgAuA94oavxmZta5ImccY4G2iHgtIvYADwOTyvpMAhZFYgUwSNLxGWLvBr4NRIHjNzOzTmQqHJJOP4h9DwO2lXxuT9uy9OkyVtJVwJsRsbabMc+U1CqpdefOnQcxfDMz60zWGcd8SSslfVPSoIwx6qStfIbQVZ9O2yV9FrgZ+F53Xx4RCyKiOSKahw4d2u1gzcwsm0yFIyIuAP4jcALQKukhSZd1E9ae9u/QCGzP2Ker9j8BmoC1kram7S9K+kKWPMzMrOcyn+OIiC3ALcB3gIuAeyRtkvRnXYSsAkZKapLUH5gCtJT1aQGmpVdXjQPejYgdXcVGxLqI+FxEDI+I4SQFZkxE/HP2lM3MrCcyrY4raTQwA/hTYBnw7yLiRUl/DLwAPF4eExH7JM0BngIagIURsUHSrHT7fGApMBFoA95Pv6PL2B5lamZmvSLrsup/C9wPfDciPuhojIjtkm7pKigilpIUh9K2+SXvA5idNbaTPsOzDN7MzHpP1sIxEfggIj4GkHQEMCAi3o+InxU2OjMzqzpZz3E8AxxV8vmzaZuZmdWZrDOOARGxu+NDROxOL401qyl+uqBZz2UtHL+XNCYiXgSQdA7wQTcxZrmMe2NBn333ihNn9tl3m9WarIXjL4GfS+q4D+N44D8UMiIzM6tqmQpHRKySdArwRZK7ujdFxN5CR2ZmZlUp64wD4FxgeBpztiQiYlEhozIzs6qV9QbAn5Es97EG+DhtDsCFw8yszmSdcTQDo9Ib9szMrI5lvY9jPeCFBM3MLPOMYwjwiqSVwEcdjRFxVSGjMjOzqpW1cHy/yEFYMYq82c3M6lfWy3F/JekkYGREPJPeNd5Q7NDMzKwaZX107HXAo8DfpU3DgCcLGpOZmVWxrCfHZwNfBt6DTx7q9LmiBmVmZtUra+H4KCL2dHyQ9Bk+/fxwMzOrA1kLx68kfRc4Kn3W+M+B/1PcsMzMrFplLRxzgZ3AOuB6kifzdfnkPzMzO3xlvapqP8mjY+8vdjhmZlbtsq5V9TqdnNOIiBG9PiIzM6tqedaq6jAA+CpwXO8Px8zMql2mcxwRsavk9WZE/A1wSbFDMzOzapT1UNWYko9HkMxAjilkRGZmVtWyHqq6q+T9PmAr8LVeH42ZmVW9rIeqLi55XRYR10XE5u7iJI2XtFlSm6S5nWyXpHvS7S+Xzmy6ipX0V2nfNZKelvTHWZM1M7Oey3qo6qZK2yPirzuJaQDuBS4D2oFVkloi4pWSbhOAkenrPOA+4LxuYu+MiP+Wfsd/Ab4HzMqSh5mZ9VzWGwCbgb8gWdxwGMlf1KNIznN0da5jLNAWEa+ly5U8DEwq6zMJWBSJFcAgScdXio2I90riB+KlT8zMDqk8D3IaExH/AiDp+8DPI+LaCjHDgG0ln9tJZhXd9RnWRfsnsZJuA6YB7wIXd/blkmYCMwFOPPHECsM0M7M8shaOE4E9JZ/3AMO7iVEnbeWzg676VIyNiJuBmyXNA+YAt36qc8QCYAFAc3OzZyVWnZ77Yd9998Xz+u67raZlLRw/A1ZKeoLkL/DJwKJuYtqBE0o+NwLbM/bpnyEW4CHgF3RSOMzMrBhZr6q6DZgB/D/gHWBGRPygm7BVwEhJTZL6A1OAlrI+LcC09OqqccC7EbGjUqykkSXxVwGbsuRgZma9I+uMA+CzwHsR8YCkoZKaIuL1rjpHxD5Jc4CnSB4zuzAiNkialW6fT7LK7kSgDXifpDh1GZvu+nZJXwT2A7/BV1SZmR1SWS/HvZXkyqovAg8A/YAHSZ4K2KWIWEpSHErb5pe8D5KnC2aKTdv/fZYxm5lZMbJejjuZ5LDQ7wEiYjtecsTMrC5lLRx70tlBAEgaWNyQzMysmmUtHI9I+juSG/SuA57BD3UyM6tL3Z7jkCRgMXAK8B7JeY7vRcSygsdmZmZVqNvCEREh6cmIOAdwsTAzq3NZD1WtkHRuoSMxM7OakPU+jouBWZK2klxZJZLJyOiiBmZmZtWpYuGQdGJEvEGy/LmZmVm3M44nSVbF/Y2kx3zznZmZdXeOo3SV2hFFDsTMzGpDd4UjunhvZmZ1qrtDVWdKeo9k5nFU+h7+cHL8jwodnfWJcW8s6OshHHK9kvNzg3u+D7MaULFwRETDoRqImZnVhqz3cZiZmQEuHGZmlpMLh5mZ5eLCYWZmubhwmJlZLi4cZmaWiwuHmZnl4sJhZma5uHCYmVkuLhxmZpaLC4eZmeVSaOGQNF7SZkltkuZ2sl2S7km3vyxpTHexku6UtCnt/4SkQUXmYGZmByqscEhqAO4leXrgKGCqpFFl3SYAI9PXTOC+DLHLgNPTx9a+CswrKgczM/u0ImccY4G2iHgtIvYADwOTyvpMAhZFYgUwSNLxlWIj4umI2JfGrwAaC8zBzMzKFFk4hgHbSj63p21Z+mSJBfhPwP/t7MslzZTUKql1586dOYduZmZdKbJwqJO28qcIdtWn21hJNwP7gH/o7MsjYkFENEdE89ChQzMM18zMsujuCYA90Q6cUPK5EdiesU//SrGSpgNXApdGhB9pa2Z2CBU541gFjJTUJKk/MAVoKevTAkxLr64aB7wbETsqxUoaD3wHuCoi3i9w/GZm1onCZhwRsU/SHOApoAFYGBEbJM1Kt88HlgITgTbgfWBGpdh0138LHAkskwSwIiJmFZWHmZkdqMhDVUTEUpLiUNo2v+R9ALOzxqbt/6qXh2lmZjn4znEzM8vFhcPMzHJx4TAzs1xcOMzMLJdCT46b1ZMXXttV2L7PHzG4sH2b5eUZh5mZ5eLCYWZmubhwmJlZLi4cZmaWiwuHmZnl4sJhZma5uHCYmVkuLhxmZpaLC4eZmeXiO8er2XM/7FH4uDeKu5PZDgM9/P06aBfP65vvtV7jGYeZmeXiwmFmZrm4cJiZWS4uHGZmlosLh5mZ5eLCYWZmubhwmJlZLi4cZmaWiwuHmZnlUmjhkDRe0mZJbZLmdrJdku5Jt78saUx3sZK+KmmDpP2Smoscv5mZfVphhUNSA3AvMAEYBUyVNKqs2wRgZPqaCdyXIXY98GfA8qLGbmZmXStyxjEWaIuI1yJiD/AwMKmszyRgUSRWAIMkHV8pNiI2RsTmAsdtZmYVFFk4hgHbSj63p21Z+mSJrUjSTEmtklp37tyZJ9TMzCoosnCok7bI2CdLbEURsSAimiOieejQoXlCzcysgiKXVW8HTij53Ahsz9inf4ZYM6tFfbWcO3hJ915S5IxjFTBSUpOk/sAUoKWsTwswLb26ahzwbkTsyBhrZmZ9oLAZR0TskzQHeApoABZGxAZJs9Lt84GlwESgDXgfmFEpFkDSZOB/AkOBX0haExFXFJWHmZkdqNAnAEbEUpLiUNo2v+R9ALOzxqbtTwBP9O5IzcwsK985bmZmubhwmJlZLoUeqjKz3vHCa7sK2e/5IwYXsl87vHnGYWZmuXjG0cfuXvZql9vGvVHMvzLNzHrCMw4zM8vFhcPMzHJx4TAzs1xcOMzMLBcXDjMzy8WFw8zMcnHhMDOzXFw4zMwsFxcOMzPLxYXDzMxyceEwM7NcXDjMzCwXL3LYned+WOjuvZChWR0o+O+Rii6e1+u7dOEwq2NFPeejaH6OSN/yoSozM8vFhcPMzHJx4TAzs1x8jsPM6kdfnqQ+jHjGYWZmuRRaOCSNl7RZUpukuZ1sl6R70u0vSxrTXayk4yQtk7Ql/XlskTmYmdmBCjtUJakBuBe4DGgHVklqiYhXSrpNAEamr/OA+4DzuomdC/xjRNyeFpS5wHeKyqNDrV62aGbW24qccYwF2iLitYjYAzwMTCrrMwlYFIkVwCBJx3cTOwn4+/T93wNfKTAHMzMrU+TJ8WHAtpLP7SSziu76DOsm9vMRsQMgInZI+lxnXy5pJjAz/bhb0uayLkOA32ZLpaodDnk4h+pxOOThHA7w3Z4En9RZY5GFQ520RcY+WWIriogFwIKutktqjYjmPPusRodDHs6hehwOeTiH4hV5qKodOKHkcyOwPWOfSrFvpYezSH++3YtjNjOzbhRZOFYBIyU1SeoPTAFayvq0ANPSq6vGAe+mh6EqxbYA09P304H/XWAOZmZWprBDVRGxT9Ic4CmgAVgYERskzUq3zweWAhOBNuB9YEal2HTXtwOPSLoGeAP46kEOscvDWDXmcMjDOVSPwyEP51AwReQ6dWBmZnXOd46bmVkuLhxmZpZLXRaO7pZCqRaSFkp6W9L6krYul1yRNC/NabOkK/pm1AeSdIKk5yRtlLRB0g1pe83kIWmApJWS1qY5/Pe0vWZy6CCpQdJLkpakn2sxh62S1klaI6k1baupPCQNkvSopE3pn43zayqHiKirF8nJ9l8DI4D+wFpgVF+Pq4uxXgiMAdaXtN0BzE3fzwX+R/p+VJrLkUBTmmNDFeRwPDAmfX8M8Go61prJg+S+oqPT9/2AfwLG1VIOJbncBDwELKnF36d0bFuBIWVtNZUHyaoX16bv+wODaimHepxxZFkKpSpExHLgd2XNXS25Mgl4OCI+iojXSa5UG3soxllJROyIiBfT9/8CbCRZGaBm8ojE7vRjv/QV1FAOAJIagT8FflLSXFM5VFAzeUj6I5J/FP4UICL2RMQ71FAO9Vg4ulrmpFYcsOQK0LHkStXnJWk4cDbJv9hrKo/0EM8akhtOl0VEzeUA/A3wbWB/SVut5QBJ0X5a0up0aSGorTxGADuBB9LDhj+RNJAayqEeC0ePlzOpUlWdl6SjgceAv4yI9yp17aStz/OIiI8j4iySVQzGSjq9Qveqy0HSlcDbEbE6a0gnbX3+/yH15YgYQ7K69mxJF1boW415fIbkEPR9EXE28HuSQ1Ndqboc6rFwZFkKpZp1teRK1eYlqR9J0fiHiHg8ba65PADSQwq/BMZTWzl8GbhK0laSw7OXSHqQ2soBgIjYnv58G3iC5LBNLeXRDrSns1aAR0kKSc3kUI+FI8tSKNWsqyVXWoApko6U1ETyjJOVfTC+A0gSybHcjRHx1yWbaiYPSUMlDUrfHwX8W2ATNZRDRMyLiMaIGE7yO/9sRPw5NZQDgKSBko7peA9cDqynhvKIiH8Gtkn6Ytp0KfAKNZRDn18h0RcvkmVOXiW5OuHmvh5PhXH+L2AHsJfkXx3XAIOBfwS2pD+PK+l/c5rTZmBCX48/HdMFJNPql4E16WtiLeUBjAZeSnNYD3wvba+ZHMry+Tf84aqqmsqB5PzA2vS1oePPbw3mcRbQmv5OPQkcW0s5eMkRMzPLpR4PVZmZWQ+4cJiZWS4uHGZmlosLh5mZ5eLCYWZmubhwmJlZLi4cZmaWy/8Hmr6BnVxDMrEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_df.groupby('Artist')['song_length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
